{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasaco\\AppData\\Local\\Temp\\ipykernel_4916\\1826793958.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './daily_data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m DATA_DIR \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     13\u001b[0m DATA_CHAPTER1 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 15\u001b[0m daily_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mDATA_CHAPTER1\u001b[39m}\u001b[39;49;00m\u001b[39mdaily_data.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\pickle.py:179\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[1;32m--> 179\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    180\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    181\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    182\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    183\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    184\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    185\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    186\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    188\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    869\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './daily_data.pickle'"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display\n",
    "\n",
    "from os import path\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# データの保存場所を指定。\n",
    "# この場合は、C:/sample/linear_regression/を読み書きする。\n",
    "WORK_DIR = './'\n",
    "DATA_DIR = './'\n",
    "DATA_CHAPTER1 = './'\n",
    "\n",
    "daily_data = pd.read_pickle(f\"{DATA_CHAPTER1}daily_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 銘柄ごとに計算するため、証券コード(SC)で集計する\n",
    "groups= daily_data.groupby('SC')\n",
    "\n",
    "data_set =[]\n",
    "for security, values in tqdm(groups):\n",
    "    # 全体の10%以上の取引日で取引のない銘柄は無視する\n",
    "    if values['株価'].isnull().sum() > values.shape[0]*0.1:  \n",
    "        continue\n",
    "    \n",
    "    # 一時的にmarket_value列を作って計算する\n",
    "    #  証券コード(SC)1、2は株価指数を表しているので、単純に指数値を入れる。\n",
    "    if security in {1, 2}: \n",
    "        values = values.assign(market_value=lambda x: x['株価'])\n",
    "    else:\n",
    "        values = values.assign(market_value=lambda x: x['時価総額（百万円）'])\n",
    "    \n",
    "    # calculate return\n",
    "    values = values.sort_values('日時')  # 時系列順でソート\n",
    "    values['収益率'] = values['market_value'].pct_change()  # 変化率の計算\n",
    "    values.drop(columns=['market_value'])  # 一時的な列を削除\n",
    "    data_set.append(values)\n",
    "\n",
    "daily_data_adj = pd.concat(data_set)  # 銘柄ごとに計算したものを結合\n",
    "\n",
    "#  極端な値を外れ値として削除。ここでは上下0.1%を外れ値とする。\n",
    "threshold = .001\n",
    "\n",
    "lower = daily_data_adj['収益率'].quantile(threshold)\n",
    "upper = daily_data_adj['収益率'].quantile(1-threshold)\n",
    "\n",
    "daily_data_adj = daily_data_adj[\n",
    "    (lower < daily_data_adj['収益率']) & (daily_data_adj['収益率'] < upper)\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wareki2datetime(wareki: str, separator:str = '.'):\n",
    "    year, month, day = wareki.split('.')\n",
    "    if year.startswith('S'):\n",
    "        year = 1925 + int(year[1:])\n",
    "    elif year.startswith('H'):\n",
    "        year = 1988 + int(year[1:])\n",
    "    elif year.startswith('R'):\n",
    "        year = 2018 + int(year[1:])\n",
    "    else:\n",
    "        NotImplementedError('S, H, R以外には使えません。')\n",
    "    return pd.datetime(year, int(month), int(day))\n",
    "\n",
    "wareki2datetime('H12.3.15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jgb_path = f'{DATA_DIR}risk_free_rate/jgbcm_all.csv'\n",
    "risk_free_rate = pd.read_csv(\n",
    "    jgb_path,\n",
    "    skiprows=1,\n",
    "    usecols=['基準日', '10年'],\n",
    "    parse_dates=['基準日'],\n",
    "    date_parser=wareki2datetime,\n",
    "    encoding='sjis',\n",
    "    index_col=['基準日'],\n",
    "    na_values='-'\n",
    ")\n",
    "\n",
    "risk_free_rate = risk_free_rate['10年'].apply(\n",
    "    # 半年複利(%表記)を日次対数収益率に変換\n",
    "    lambda x: np.log(1 + .01 * .5 * x) / 125 \n",
    ").apply(\n",
    "    # 単利へ変換\n",
    "    lambda x: np.exp(x) -1 \n",
    ")\n",
    "risk_free_rate.rename('安全資産利子率', inplace=True)\n",
    "risk_free_rate.index.rename('日時', inplace=True)\n",
    "\n",
    "risk_free_rate = pd.DataFrame(risk_free_rate)\n",
    "\n",
    "# 出力して結果を確認\n",
    "display(risk_free_rate.dropna().head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_return_and_risk_free_return = pd.merge(\n",
    "    daily_data_adj[daily_data_adj['SC']>2],  # 指数を除く\n",
    "    risk_free_rate, on='日時'\n",
    ")  \n",
    "\n",
    "# SCと日時をindexにする\n",
    "stock_return_and_risk_free_return.set_index(\n",
    "    ['SC', '日時'],\n",
    "    verify_integrity=True, \n",
    "    inplace=True\n",
    ")  \n",
    "\n",
    "# 出力して結果を確認\n",
    "display(stock_return_and_risk_free_return.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 日時で集計\n",
    "group_by_date = stock_return_and_risk_free_return.groupby('日時')  \n",
    "\n",
    "data_with_market_returns = []\n",
    "for date, values in tqdm(group_by_date):\n",
    "    sum_of_market_capital = values['時価総額（百万円）'].sum()\n",
    "    values = values.assign(\n",
    "        # returnが全てnullならnullにする\n",
    "        市場収益率=lambda x: (\n",
    "            x['収益率'] * (x['時価総額（百万円）'] / sum_of_market_capital)\n",
    "        ).sum(\n",
    "            min_count=1\n",
    "        )\n",
    "    )\n",
    "    data_with_market_returns.append(values)\n",
    "\n",
    "data_with_market_returns = pd.concat(data_with_market_returns)\n",
    "\n",
    "display(data_with_market_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_excess_returns = data_with_market_returns.assign(\n",
    "    超過収益率=lambda x: x['収益率'] - x['安全資産利子率'],\n",
    "    市場超過収益率=lambda x: x['市場収益率'] - x['安全資産利子率']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 扱いやすくするためにindexを通常の列に戻す\n",
    "temporary_data_excess_returns = data_with_excess_returns.reset_index()  \n",
    "\n",
    "# read financial data\n",
    "financial_data = pd.read_pickle(f'{DATA_CHAPTER1}financial_data_all.pickle')\n",
    "\n",
    "# 利用しない列を削除\n",
    "financial_data.drop(\n",
    "    columns=['発行済株式数', '日時'],\n",
    "    inplace=True\n",
    ")  \n",
    "\n",
    "# 決算発表当日の株価データとマージできるように、株価データに決算発表日を張る\n",
    "group_by_security = temporary_data_excess_returns.groupby('SC')\n",
    "\n",
    "temporary_list = []\n",
    "for security, values in tqdm(group_by_security):\n",
    "    # 財務データから決算発表日を取得 \n",
    "    # 例: array(\n",
    "    #         ['2016-05-11T00:00:00.000000000',\n",
    "    #          '2017-05-11T00:00:00.000000000'],\n",
    "    #         dtype='datetime64[ns]'\n",
    "    #     )\n",
    "    announcement_dates = financial_data[\n",
    "        '決算発表日（本決算）'\n",
    "    ][\n",
    "        financial_data.SC == security\n",
    "    ].dropna().unique() \n",
    "    # 古い順にソートしてnp.arrayに戻す\n",
    "    announcement_dates = pd.Series(announcement_dates).sort_values().values\n",
    "    \n",
    "    # 収益率データの「日時」が含まれる決算期を意味するカテゴリカル変数を作る。\n",
    "    # 例: 「日時」が2016-05-11より前 → 欠損値、 \n",
    "    #     「日時」が2016-05-11～2017-05-10 → 2016-05-11、など\n",
    "    aligned = values.assign(\n",
    "        announcement_date=lambda x: pd.cut(\n",
    "            x['日時'],\n",
    "            (\n",
    "                list(announcement_dates)\n",
    "            ) + [np.datetime64(values['日時'].max() + pd.offsets.Day())],\n",
    "            labels=announcement_dates,\n",
    "            right=False\n",
    "        ).astype(\n",
    "            np.datetime64\n",
    "        )\n",
    "    )\n",
    "    temporary_list.append(aligned)\n",
    "\n",
    "temporary_data_excess_returns = pd.concat(temporary_list)\n",
    "temporary_data_excess_returns.rename(\n",
    "    columns={'announcement_date':'決算発表日（日時）'},\n",
    "    inplace=True\n",
    ")\n",
    "del temporary_list\n",
    "\n",
    "# 財務データを決算発表日について一意にする\n",
    "financial_data = financial_data.groupby(\n",
    "    ['SC', '決算発表日（本決算）']\n",
    ").first().reset_index()\n",
    "\n",
    "excess_returns_with_financial_data = pd.merge(\n",
    "    temporary_data_excess_returns,\n",
    "    financial_data,\n",
    "    left_on=['SC','名称', '決算発表日（日時）'],\n",
    "    right_on=['SC','名称', '決算発表日（本決算）'],\n",
    "    how='left'\n",
    ")\n",
    "excess_returns_with_financial_data.set_index(\n",
    "    ['SC', '日時'],\n",
    "    inplace=True,\n",
    "    verify_integrity=True\n",
    ")\n",
    "\n",
    "del temporary_data_excess_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをpickleで保存\n",
    "excess_returns_with_financial_data.to_pickle(\n",
    "    f'{DATA_DIR}excess_returns_with_financial_data.pickle'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
