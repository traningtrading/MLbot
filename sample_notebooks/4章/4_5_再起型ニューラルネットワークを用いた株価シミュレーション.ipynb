{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.55　ライブラリのインポートとデータの取込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "plt.rcParams['font.family'] = 'Yu Mincho'\n",
    "\n",
    "# C:\\sample\\rnn_simulationに読み書き\n",
    "WORK_DIR = os.path.join('C:\\\\', 'sample', 'rnn_simulation')\n",
    "\n",
    "dji = pd.read_csv(\n",
    "    os.path.join(\n",
    "        WORK_DIR, \n",
    "        'data',\n",
    "        'DJI.csv'\n",
    "    ), \n",
    "    parse_dates=['Date'],\n",
    "    engine='python'\n",
    ")\n",
    "dji = dji.assign(ログリターン=np.log(dji.loc[:, 'Adj Close']).diff())\n",
    "dji = dji.iloc[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.56　メタパラメータの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "lookback_size = 64\n",
    "num_hidden_neurons = 40\n",
    "num_hidden_layers = 3\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ソースコード4.57　入力値と出力値の箱を用意（RecurrentSimulationNetクラスから抜粋）\n",
    "* ソースコード4.58　ネットワークの再起型コネクションのある部分（RecurrentSimulationNetクラスから抜粋）\n",
    "* ソースコード4.59　ネットワークの出力から分布の定義（RecurrentSimulationNetクラスから抜粋）\n",
    "* ソースコード4.60　ネットワークの出力と学習ステップを定義（RecurrentSimulationNetクラスから抜粋）\n",
    "* ソースコード4.61　ステートを考慮した学習メソッド（RecurrentSimulationNetクラスから抜粋）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentSimulationNet:\n",
    "    def __init__(\n",
    "        self, sess, batch_size, lookback_size,\n",
    "        num_hidden_neurons, num_hidden_layers,\n",
    "        learning_rate,  momentum=0.9, training=False\n",
    "    ):\n",
    "# --- ソースコード4.57 ---\n",
    "        self._inputs = tf.placeholder(\n",
    "            tf.float32, [batch_size, lookback_size], name='inputs'\n",
    "        )\n",
    "        self._labels = tf.placeholder(\n",
    "            tf.float32, [batch_size, lookback_size], name='labels'\n",
    "        )\n",
    "# --- ソースコード4.57 ここまで ---\n",
    "\n",
    "# --- ソースコード4.58 ---\n",
    "        self._inputs_normed = tf.layers.batch_normalization(\n",
    "            tf.expand_dims(self._inputs, axis=-1),\n",
    "            momentum=momentum, training=training\n",
    "        )\n",
    "                \n",
    "        with tf.variable_scope('recurrent_part'):\n",
    "            rnn_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "                [\n",
    "                    tf.nn.rnn_cell.LSTMCell(num_units=num_hidden_neurons)\n",
    "                    for _ in range(num_hidden_layers)\n",
    "                ]\n",
    "            )\n",
    "            self._initial_state = rnn_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "            self._rnn_outputs, self._final_state = tf.nn.dynamic_rnn(\n",
    "                rnn_cell, \n",
    "                self._inputs_normed, \n",
    "                initial_state=self._initial_state\n",
    "            )\n",
    "# --- ソースコード4.58 ここまで ---\n",
    "# --- ソースコード4.59 ---\n",
    "        with tf.variable_scope('distribution'):\n",
    "            self._dist_loc = tf.squeeze(\n",
    "                tf.layers.dense(self._rnn_outputs, 1), axis=-1\n",
    "            )\n",
    "            self._dist_scale = tf.squeeze(\n",
    "                tf.nn.softplus(tf.layers.dense(self._rnn_outputs, 1)),\n",
    "                axis=-1\n",
    "            )\n",
    "            self._distributions = tf.contrib.distributions.StudentT(\n",
    "                df=3.0, loc=self._dist_loc, scale=self._dist_scale\n",
    "            )\n",
    "# --- ソースコード4.59 ここまで ---\n",
    "# --- ソースコード4.60 ---\n",
    "        with tf.variable_scope('outputs'):\n",
    "            self._dist_sample_size = tf.get_variable(\n",
    "                'sample_size', (), dtype=tf.int32, trainable=False\n",
    "            )\n",
    "            self._dist_sample = self._distributions.sample(\n",
    "                self._dist_sample_size\n",
    "            )\n",
    "            self._log_likelihood = tf.reduce_mean(\n",
    "                tf.log(\n",
    "                    self._distributions.prob(self._labels)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        update_ops = tf.get_collection(\n",
    "            tf.GraphKeys.UPDATE_OPS\n",
    "        )\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self._training_step = tf.train.AdamOptimizer(\n",
    "                learning_rate\n",
    "            ).minimize(\n",
    "                -self._log_likelihood\n",
    "            )\n",
    "    \n",
    "        self.ssn_saver = tf.train.Saver()    \n",
    "        if training:\n",
    "            sess.run(\n",
    "                tf.global_variables_initializer()\n",
    "            )\n",
    "# --- ソースコード4.60 ここまで ---\n",
    "# --- ソースコード4.61 ---\n",
    "    def train_one_step(\n",
    "        self, sess, prev_samples, target_samples, state=None\n",
    "    ):\n",
    "        fetches = [\n",
    "            self._training_step,\n",
    "            self._log_likelihood,\n",
    "            self._final_state\n",
    "        ]\n",
    "        feed_dict = {\n",
    "            self._inputs: prev_samples,\n",
    "            self._labels: target_samples\n",
    "        }\n",
    "        if state is not None:\n",
    "            feed_dict = {\n",
    "                **feed_dict,\n",
    "                self._initial_state: state\n",
    "            }\n",
    "        return sess.run(\n",
    "            fetches=fetches, feed_dict=feed_dict\n",
    "        )\n",
    "# --- ソースコード4.61 ここまで ---\n",
    "    \n",
    "    def sample(\n",
    "        self, sess, prev_samples, sample_size=1, state=None\n",
    "    ):\n",
    "        fetches = [\n",
    "            self._dist_sample,\n",
    "            self._final_state\n",
    "        ]\n",
    "        feed_dict = {\n",
    "            self._inputs: prev_samples,\n",
    "            self._dist_sample_size: sample_size\n",
    "        }\n",
    "        if state is not None:\n",
    "            feed_dict = {\n",
    "                **feed_dict,\n",
    "                self._initial_state: state\n",
    "            }\n",
    "        return sess.run(fetches=fetches, feed_dict=feed_dict)    \n",
    "    \n",
    "    def save(self, sess, path):\n",
    "        self.ssn_saver.save(sess, path)\n",
    "        print(f'model saved in {path}')\n",
    "        \n",
    "    def restore(self, sess, path):\n",
    "        self.ssn_saver.restore(sess, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.62　エポックに分割した学習のためのメタパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "steps_per_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.63　ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "likelihoods_over_time = np.empty(max_epochs)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Graph().as_default() and tf.Session() as session:\n",
    "    rec_sim_net = RecurrentSimulationNet(\n",
    "        session, batch_size, lookback_size,\n",
    "        num_hidden_neurons, num_hidden_layers,\n",
    "        learning_rate, training=True\n",
    "    )\n",
    "    for epoch in range(max_epochs):\n",
    "        random_row_indices = np.random.choice(\n",
    "            dji.shape[0] - lookback_size * (steps_per_epoch+1) - 1,\n",
    "            size=batch_size,\n",
    "            replace=True\n",
    "        )\n",
    "        random_rows = [\n",
    "            dji.iloc[\n",
    "                random_row:random_row + lookback_size*(steps_per_epoch+1),\n",
    "                :\n",
    "            ]\n",
    "            for random_row in random_row_indices\n",
    "        ]\n",
    "        log_returns_for_this_epoch = np.reshape(\n",
    "            [row[['ログリターン']].values for row in random_rows],\n",
    "            (batch_size, lookback_size*(steps_per_epoch + 1))\n",
    "        )\n",
    "        state = None\n",
    "        likelihood_mean_epoch = 0.\n",
    "        \n",
    "        for training_step in range(steps_per_epoch):\n",
    "            _, log_likelihood, state = rec_sim_net.train_one_step(\n",
    "                session,\n",
    "                log_returns_for_this_epoch[\n",
    "                    :,\n",
    "                    lookback_size*training_step:lookback_size*(training_step + 1)\n",
    "                ],\n",
    "                log_returns_for_this_epoch[\n",
    "                    :,\n",
    "                    lookback_size*training_step + 1:lookback_size*(training_step + 1) + 1\n",
    "                ],\n",
    "                state=state\n",
    "            )\n",
    "            likelihood_mean_epoch += log_likelihood\n",
    "        likelihoods_over_time[epoch] = likelihood_mean_epoch / steps_per_epoch\n",
    "        likelihood_mean_polling_interval = 0.\n",
    "        print(\n",
    "            f'[{(100*epoch) // max_epochs:3}%] '\n",
    "            f'直近{steps_per_epoch}ステップの平均尤度：'\n",
    "            f'{likelihoods_over_time[epoch]:.5f}'\n",
    "        )\n",
    "    rec_sim_net.save(\n",
    "        session, os.path.join(\n",
    "            WORK_DIR,\n",
    "            'models',\n",
    "            'recurrent_simulation_net'\n",
    "        )\n",
    "    )\n",
    "likelihoods_over_time_copy = likelihoods_over_time.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.64　対数尤度のグラフ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.lineplot(\n",
    "    x=list(range(likelihoods_over_time.shape[0])),\n",
    "    y=likelihoods_over_time,\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.65　シミュレーション用のメタパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_batch_size = 1\n",
    "sim_lookback_size = 1\n",
    "sim_warmup_size = 64 # ウォームアップステップの回数\n",
    "sim_steps = 100 # シミュレーションの回数\n",
    "\n",
    "# シミュレーション値を保存するための配列を予め用意する\n",
    "gen_returns = np.empty((sim_batch_size, sim_warmup_size + sim_steps))\n",
    "\n",
    "# 実際のリターンを保存するための配列を用意する。サイズはgen_return と同じ。\n",
    "real_returns = np.empty_like(gen_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.66　ログリターンの疑似データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() and tf.Session() as session:\n",
    "    rec_sim_net = RecurrentSimulationNet(\n",
    "        session, sim_batch_size,\n",
    "        sim_lookback_size,\n",
    "        num_hidden_neurons,\n",
    "        num_hidden_layers,\n",
    "        learning_rate,\n",
    "        training=False # 学習ステップでないので、training はFalse\n",
    "    )\n",
    "    \n",
    "    # 学習したウェイトを適用\n",
    "    rec_sim_net.restore(\n",
    "        session, os.path.join(\n",
    "            WORK_DIR, 'models', 'recurrent_simulation_net'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ウォームアップ\n",
    "    state = None  # ステートを初期化\n",
    "    \n",
    "    # ウォームアップの開始地点をランダムに設定。\n",
    "    # ここではバッチサイズが1 なので1 つ返ってくる。\n",
    "    random_row_indices = np.random.choice(\n",
    "        dji.shape[0] - sim_warmup_size - 1,\n",
    "        size=sim_batch_size,\n",
    "        replace=True\n",
    "    )\n",
    "    \n",
    "    # 実リターンを予め用意した配列に保存\n",
    "    real_returns[:, :] = np.reshape(\n",
    "        [\n",
    "            dji.iloc[\n",
    "                random_row:random_row + sim_warmup_size + sim_steps, :\n",
    "            ][['ログリターン']].values\n",
    "            for random_row in random_row_indices\n",
    "        ],\n",
    "        real_returns.shape\n",
    "    )\n",
    "    \n",
    "    # ウォームアップステップ用に実データを保存\n",
    "    gen_returns[:, :sim_warmup_size] = np.reshape(\n",
    "        [\n",
    "            dji.iloc[\n",
    "                random_row:random_row + sim_warmup_size, :\n",
    "            ][['ログリターン']].values\n",
    "            for random_row in random_row_indices\n",
    "        ],\n",
    "        (sim_batch_size, sim_warmup_size))\n",
    "    \n",
    "    for warmup_step in range(sim_warmup_size):\n",
    "        samples, state = rec_sim_net.sample(\n",
    "            session,\n",
    "            np.reshape( # 実データを渡す\n",
    "                [\n",
    "                    dji.iloc[\n",
    "                        random_row + warmup_step, :]\n",
    "                    [['ログリターン']].values\n",
    "                    for random_row in random_row_indices\n",
    "                ],  \n",
    "                (sim_batch_size, 1)\n",
    "            ),\n",
    "            state=state  # state のみ保存して、sample は保存しない\n",
    "        )\n",
    "    samples = np.squeeze(samples, axis=-1)\n",
    "\n",
    "    # シミュレーション\n",
    "    for sim_step in range(sim_steps):\n",
    "        samples, state = rec_sim_net.sample(\n",
    "            session,\n",
    "            samples,  # シミュレーション値を渡す\n",
    "            state=state\n",
    "        )\n",
    "        samples = np.squeeze(samples, axis=-1)\n",
    "        gen_returns[:, sim_step + sim_warmup_size] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.67　ログリターンから指数値の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_returns_df = pd.DataFrame(\n",
    "    np.transpose(real_returns), columns=['real_returns']\n",
    ")\n",
    "real_returns_df = real_returns_df.assign(\n",
    "    real_pf=np.exp(real_returns_df.loc[:, 'real_returns']).cumprod()\n",
    ")\n",
    "\n",
    "gen_returns_df = pd.DataFrame(\n",
    "    np.transpose(gen_returns), columns=['gen_returns']\n",
    ")\n",
    "gen_returns_df = gen_returns_df.assign(\n",
    "    gen_pf=np.exp(gen_returns_df.loc[:, 'gen_returns']).cumprod()\n",
    ")\n",
    "\n",
    "sim_data = real_returns_df.join(gen_returns_df)\n",
    "sim_data = sim_data.loc[\n",
    "    :, ['real_pf', 'gen_pf']\n",
    "].stack().reset_index()\n",
    "sim_data.columns = ['t', 'type', 'pf_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.68　指数値をグラフ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.lineplot(x='t', y='pf_value', hue='type', data=sim_data, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
