{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "from scipy.stats import norm, t\n",
    "from IPython.core.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "\n",
    "plt.rcParams['font.family'] = 'Yu Mincho'\n",
    "\n",
    "# C:\\sample\\neural_net_simulation に保存\n",
    "WORK_DIR = os.path.join('C:\\\\', 'sample', 'neural_net_simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.39　ダウ・ジョーンズデータの取込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dji = pd.read_csv(\n",
    "    os.path.join(WORK_DIR, 'data', 'DJI.csv'), \n",
    "    parse_dates=['Date'],\n",
    "    engine='python'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.40　ログリターンの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dji = dji.assign(ログリターン=np.log(dji.loc[:, 'Adj Close']).diff())\n",
    "dji = dji.iloc[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.41　ログリターンのヒストグラムとフィットした正規分布のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dji.loc[1:, 'ログリターン'], fit=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.42　ログリターンのヒストグラムとフィットしたt分布のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(dji.loc[1:, 'ログリターン'], fit=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ソースコード4.43: ニューラルネットワークの入力と期待出力（バッチ考慮後）（IndexSimulationNet クラスから抜粋）\n",
    "* ソースコード4.44　 バッチ標準化付きニューラルネットワークの隠れ層（IndexSimulationNetクラスから抜粋）\n",
    "* ソースコード4.45　 隠れ層からドリフト項とボラティリティ項を作成し、分布オブジェクトでまとめる（IndexSimulationNetクラスから抜粋）\n",
    "* ソースコード4.46　平均尤度の定義（IndexSimulationNetクラスから抜粋）\n",
    "* ソースコード4.47　学習メソッド（IndexSimulationNetクラスから抜粋）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexSimulationNet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sess,\n",
    "        batch_size,\n",
    "        lookback_size,\n",
    "        num_hidden_neurons,\n",
    "        num_hidden_layers,\n",
    "        learning_rate, \n",
    "        momentum=0.8,\n",
    "        training=False\n",
    "    ):\n",
    "# --- ソースコード4.43 ---\n",
    "        with tf.variable_scope('input_layer'):\n",
    "            self._inputs = tf.placeholder(tf.float32, [batch_size, lookback_size], name='inputs')\n",
    "            self._labels = tf.placeholder(tf.float32, [batch_size, 1], name='label')\n",
    "# --- ソースコード4.43 ここまで ---            \n",
    "\n",
    "        with tf.variable_scope('hidden_layers'):\n",
    "# --- ソースコード4.44 ---\n",
    "            self._inputs_normed = tf.layers.batch_normalization(\n",
    "                tf.expand_dims(self._inputs, axis=-1),\n",
    "                momentum=momentum,\n",
    "                training=training\n",
    "            )\n",
    "            self._hidden_layer = tf.squeeze(self._inputs_normed, axis=-1)\n",
    "            \n",
    "            for layer in range(num_hidden_layers):\n",
    "                self._hidden_layer = tf.layers.dense(\n",
    "                    self._hidden_layer, \n",
    "                    num_hidden_neurons,\n",
    "                    activation=tf.tanh\n",
    "                )\n",
    "# --- ソースコード4.44 ここまで ---\n",
    "                \n",
    "        with tf.variable_scope('distribution'):\n",
    "# --- ソースコード4.45 ---\n",
    "            self._scale = tf.nn.softplus(\n",
    "                tf.layers.dense(\n",
    "                    self._hidden_layer,\n",
    "                    1,\n",
    "                    name='scale'\n",
    "                )\n",
    "            )  # ボラティリティ項。ソフトプラス関数を最後にかける。\n",
    "            \n",
    "            self._loc = tf.layers.dense(\n",
    "                self._hidden_layer, 1, name='loc')\n",
    "            self._distr = tf.distributions.StudentT(df=3., loc=self._loc, scale=self._scale)\n",
    "# --- ソースコード4.45 ここまで ---\n",
    "            \n",
    "        with tf.variable_scope('outputs'):\n",
    "# --- ソースコード4.46  ---\n",
    "            self._sample_size = tf.get_variable(\n",
    "                'sample_size', 1, dtype=tf.int32, trainable=False\n",
    "            )\n",
    "            # 分布からサンプリング\n",
    "            self._sample = self._distr.sample(self._sample_size)\n",
    "        \n",
    "            # 対数尤度の平均\n",
    "            self._log_likelihood = tf.reduce_mean(\n",
    "                tf.log(\n",
    "                    self._distr.prob(self._labels) \n",
    "                )\n",
    "            )\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            \n",
    "            # バッチ標準化の更新ステップを追加\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self._training_step = tf.train.AdamOptimizer(\n",
    "                    learning_rate=learning_rate\n",
    "                ).minimize(\n",
    "                    -self._log_likelihood  # 対数尤度にマイナスをかけたものを最小化\n",
    "                )\n",
    "# --- ソースコード4.46 ここまで ---\n",
    "        \n",
    "        if training:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self._saver = tf.train.Saver()\n",
    "        \n",
    "    def train_one_step(self, sess, inputs, labels):\n",
    "# --- ソースコード4.47 ---\n",
    "        fetches = [\n",
    "            self._training_step,\n",
    "            self._log_likelihood\n",
    "        ]\n",
    "        feed_dict = {\n",
    "            self._inputs: inputs,\n",
    "            self._labels: labels\n",
    "        }\n",
    "        return sess.run(fetches, feed_dict)\n",
    "# --- ソースコード4.47 ここまで ---\n",
    "    \n",
    "    def sample(self, sess, inputs, sample_size=(1,)):\n",
    "        return sess.run(\n",
    "            fetches=[\n",
    "                self._sample,\n",
    "                self._scale,\n",
    "                self._loc,\n",
    "            ],\n",
    "            feed_dict={\n",
    "                self._inputs: inputs,\n",
    "                self._sample_size: sample_size\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def save(self, sess, path):\n",
    "        self._saver.save(sess, path)\n",
    "        print(f'model saved in {path}')\n",
    "        \n",
    "    def restore(self, sess, path):\n",
    "        self._saver.restore(sess, path)\n",
    "        print(f'model restored from {path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.48　ニューラルネットワークのメタパラメータを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_size = 32\n",
    "batch_size = 32\n",
    "num_hidden_neurons = 128\n",
    "num_hidden_layers = 3\n",
    "max_learn_steps = 20000\n",
    "polling_interval = 500\n",
    "learning_rate = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.49　シミュレーション用ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods_over_time = np.empty(max_learn_steps // polling_interval)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Graph().as_default() and tf.Session() as session:\n",
    "    index_sim_net = IndexSimulationNet(\n",
    "        session, batch_size, lookback_size,\n",
    "        num_hidden_neurons, num_hidden_layers, learning_rate,\n",
    "        training=True\n",
    "    )\n",
    "    \n",
    "    likelihood_mean_polling_interval = 0.\n",
    "    \n",
    "    for learn_step in range(max_learn_steps):\n",
    "        random_row_indices = np.random.choice(\n",
    "            dji.shape[0] - lookback_size - 1, size=batch_size, replace=True\n",
    "        )\n",
    "        random_rows = [\n",
    "            dji.iloc[random_row:random_row + lookback_size + 1, :] \n",
    "            for random_row in random_row_indices\n",
    "        ]\n",
    "        log_returns_for_this_step = np.reshape(\n",
    "           [row[['ログリターン']].values for row in random_rows],\n",
    "            (batch_size, lookback_size + 1)\n",
    "        )\n",
    "        \n",
    "        _, log_likelihood = index_sim_net.train_one_step(\n",
    "            session,\n",
    "            log_returns_for_this_step[:, :lookback_size],\n",
    "            log_returns_for_this_step[:, lookback_size:]\n",
    "        )\n",
    "        likelihood_mean_polling_interval += log_likelihood\n",
    "        if learn_step % polling_interval == 0:\n",
    "            likelihoods_over_time[\n",
    "                learn_step // polling_interval\n",
    "            ] = likelihood_mean_polling_interval / polling_interval\n",
    "            \n",
    "            likelihood_mean_polling_interval = 0.\n",
    "            print(f'[{(learn_step * 100) // max_learn_steps:3}%] '\n",
    "                  f'直近{polling_interval}ステップの平均尤度：'\n",
    "                  f'{likelihoods_over_time[learn_step // polling_interval]:.5f}')\n",
    "            \n",
    "    index_sim_net.save(session, os.path.join(WORK_DIR, 'models', 'index_sim_dji'))\n",
    "likelihoods_over_time_copy = likelihoods_over_time.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ステップに対しての平均尤度\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.lineplot(x=list(range(likelihoods_over_time.shape[0])), y=likelihoods_over_time, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.50　ログリターン用の箱の用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim_steps = 100\n",
    "sim_start_index = np.random.randint(\n",
    "    0,\n",
    "    dji.shape[0] - lookback_size - num_sim_steps\n",
    ")\n",
    "real_log_returns = dji.iloc[\n",
    "    sim_start_index:sim_start_index + lookback_size + num_sim_steps, :\n",
    "][['ログリターン']].values.flatten()\n",
    "gen_log_returns = real_log_returns.copy()\n",
    "path_dates = dji.iloc[\n",
    "    sim_start_index:sim_start_index + lookback_size + num_sim_steps, :\n",
    "][['Date']].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.51　一つのパスのシミュレーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_scales = np.empty(num_sim_steps)\n",
    "gen_locs = np.empty_like(gen_scales)\n",
    "gen_dfs = np.empty_like(gen_scales)\n",
    "\n",
    "sim_batch_size = 1\n",
    "\n",
    "print(f'{pd.to_datetime(path_dates[lookback_size]):%Y-%m-%d}'\n",
    "      f' ～ {pd.to_datetime(path_dates[~0]):%Y-%m-%d}'\n",
    "      ' のログリターンをシミュレーションします。')\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default() and tf.Session() as sess:\n",
    "    index_sim_net = IndexSimulationNet(\n",
    "        session,\n",
    "        sim_batch_size,\n",
    "        lookback_size,\n",
    "        num_hidden_neurons,\n",
    "        num_hidden_layers,\n",
    "        learning_rate,\n",
    "        training=False\n",
    "    )\n",
    "    index_sim_net.restore(\n",
    "        sess,\n",
    "        os.path.join(WORK_DIR, 'models', 'index_sim_dji')\n",
    "    )\n",
    "    \n",
    "    rolling_log_returns = np.array(\n",
    "        [real_log_returns[:lookback_size]]\n",
    "    )\n",
    "    for sim_step in range(num_sim_steps):\n",
    "        sample, scale, loc = index_sim_net.sample(\n",
    "            sess,\n",
    "            rolling_log_returns,\n",
    "            [1])\n",
    "        rolling_log_returns[:, :~0] = rolling_log_returns[:, 1:]\n",
    "        rolling_log_returns[:, ~0] = sample\n",
    "        \n",
    "        gen_log_returns[lookback_size + sim_step] = sample\n",
    "        gen_scales[sim_step] = scale\n",
    "        gen_locs[sim_step] = loc\n",
    "    print(f'{num_sim_steps}個のログリターンをシミュレーションしました。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.52　指数値の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_log_returns = pd.DataFrame(\n",
    "    data=np.transpose([gen_log_returns, real_log_returns]),\n",
    "    columns=['シミュレーション値', '実際値'],\n",
    "    index=path_dates\n",
    ")\n",
    "asset_values = np.exp(both_log_returns).cumprod().stack().reset_index()\n",
    "asset_values.columns = ['日付', 'タイプ', 'アセット価値']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソースコード4.53　指数値のパスのプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.lineplot(data=asset_values, x='日付', y='アセット価値', hue='タイプ', ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
